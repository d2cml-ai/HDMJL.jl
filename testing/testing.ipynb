{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0e7ace-af01-4a54-8ed7-42c5d0d17f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, Tables, TableOperations, StatsBase, FreqTables, DataFrames, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be004187-fae5-4f3e-a8e7-4d622c814f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvec (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cvec(a)\n",
    "    \"\"\" Turn a list or vector-like object into a proper column vector\n",
    "    Input\n",
    "    a: List or vector-like object, has to be a potential input for np.array()\n",
    "    Output\n",
    "    vec: two dimensional NumPy array, with the first dimension weakly greater\n",
    "         than the second (resulting in a column vector for a vector-like input)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Conver input into a two dimensional NumPy array\n",
    "    vec = cat([a], dims = 2) \n",
    "\n",
    "    # Check whether the second dimension is strictly greater than the first\n",
    "    # (remembering Python's zero indexing)\n",
    "    \n",
    "    if size(vec)[1] < size(vec)[2]\n",
    "        # If so, transpose the input vector\n",
    "        vec = transpose(vec)\n",
    "    end\n",
    "   \n",
    "    # Return the column vector\n",
    "    return vec\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12505837-9831-4818-8cc2-497cee4dedf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corre (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Statistics.cor\n",
    "function corre(y, X)\n",
    "    \n",
    "    \"\"\" Return correlation coefficients between columns of matrices\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array\n",
    "    X: n by k NumPy array\n",
    "    Outputs\n",
    "    corr: list of length k, where the k-th element is the correlation\n",
    "          coefficient between y and the k-th column of X\n",
    "    \"\"\"\n",
    "    # Concatenate y and X into a single NumPy array\n",
    "    yX = hcat(y, X)\n",
    "    \n",
    "    # Get the correlation coefficients between all columns of that array\n",
    "    corr = cor(yX)\n",
    "    \n",
    "    # Get the first row, starting at the first off-diagonal element (these are\n",
    "    # the correlation coefficients between y and each column of X\n",
    "    corr = corr[1, :] \n",
    "    \n",
    "    # Return the result\n",
    "    return corr\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f673c3ea-250a-420a-aff2-b17895cd17e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_values (generic function with 3 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_values(X, y, number::Int64=5, intercetp::Bool=true)\n",
    "    \"\"\" Return an initial parameter guess for a LASSO model\n",
    "    Inputs\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    X: n by k NumPy array, RHS variables\n",
    "    Outputs\n",
    "    residuals: n ny 1 NumPy array, residuals for initial parameter guess\n",
    "    coefficients: k by 1 NumPy array, initial coefficient values\n",
    "    \"\"\"\n",
    "    # Make sure y is a proper column vector\n",
    "    #y = cvec(y)\n",
    "    \n",
    "    # Get the absolute value of correlations between y and X\n",
    "    corr = broadcast(abs, cor(y, X)[1, :])\n",
    "    \n",
    "    # Get the number of columns of X\n",
    "    kx = size(X)[2]\n",
    "    \n",
    "    # Make an index selecting the five columns of X which are most correlated\n",
    "    # with y (since .argsort() always sorts in increasing order, selecting from\n",
    "    # the back gets the most highly correlated columns)\n",
    "    index = sortperm(corr, rev=true)[1: min(number, kx)]\n",
    "    \n",
    "    # Set up an array of coefficient guesses\n",
    "    coefficients = zeros(kx)\n",
    "    \n",
    "    # Regress y on the five most correlated columns of X, including an intercept\n",
    "    # if desired\n",
    "   reg = lm(X[:, index], y)\n",
    "    \n",
    "    # Replace the guesses for the estimated coefficients (note that .coef_ does\n",
    "    # not return the estimated intercept, if one was included in the model)\n",
    "    \n",
    "    coefficients[index] = GLM.coef(reg)\n",
    "    \n",
    "    # Replace any NANs as zeros\n",
    "    replace!(coefficients, NaN=>0)\n",
    "    \n",
    "    # Get the regression residuals\n",
    "    residuals = y - predict(reg, X[:, index])\n",
    "    \n",
    "    return residuals, reg, index, coefficients, corr\n",
    "    #return index\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444c5c47-65ba-4921-99f1-1f9e19d6a2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoShooting_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LassoShooting_fit( ;x, y, lmbda, maxIter::Int = 1000, \n",
    "                            optTol::Float64 = 10^(-5), \n",
    "                            zeroThreshold::Float64 = 10^(-6),\n",
    "                            XX = nothing, Xy = nothing, beta_start = nothing)\n",
    "        \n",
    "     \"\"\" Shooting LASSO algorithm with variable dependent penalty weights\n",
    "    Inputs\n",
    "    x: n by p NumPy array, RHS variables\n",
    "    y: n by 1 NumPy array, outcome variable\n",
    "    lmbda: p by 1 NumPy array, variable dependent penalty terms. The j-th\n",
    "           element is the penalty term for the j-th RHS variable.\n",
    "    maxIter: integer, maximum number of shooting LASSO updated\n",
    "    optTol: scalar, algorithm terminated once the sum of absolute differences\n",
    "            between the updated and current weights is below optTol\n",
    "    zeroThreshold: scalar, if any final weights are below zeroThreshold, they\n",
    "                   will be set to zero instead\n",
    "    XX: k by k NumPy array, pre-calculated version of x'x\n",
    "    Xy: k by 1 NumPy array, pre-calculated version of x'y\n",
    "    beta_start: k by 1 NumPy array, initial weights\n",
    "    Outputs\n",
    "    w: k by 1 NumPy array, final weights\n",
    "    wp: k by m + 1 NumPy array, where m is the number of iterations the\n",
    "        algorithm took. History of weight updates, starting with the initial\n",
    "        weights.\n",
    "    m: integer, number of iterations the algorithm took\n",
    "    \"\"\"\n",
    "    n = size(x)[1]\n",
    "    p = size(x)[2]\n",
    "    \n",
    "    # Check whether XX and Xy were provided, calculate them if not\n",
    "    if (isnothing(XX))\n",
    "        XX = x'*x\n",
    "    end\n",
    "\n",
    "    if (isnothing(Xy))\n",
    "        Xy = x'*y\n",
    "    end\n",
    "\n",
    "    # Check whether an initial value for the intercept was provided\n",
    "\n",
    "    if (isnothing(beta_start))\n",
    "        # If not, use init_values from help_functions, which will return\n",
    "        # regression estimates for the five variables in x which are most\n",
    "        # correlated with y, and initialize all other coefficients as zero\n",
    "        beta = init_values(x, y)[4]\n",
    "\n",
    "    else\n",
    "        # Otherwise, use the provided initial weights\n",
    "        beta = beta_start\n",
    "    end\n",
    "\n",
    "    # Set up a history of weights over time, starting with the initial ones\n",
    "    wp = beta\n",
    "\n",
    "    # Keep track of the number of iterations\n",
    "    m = 1\n",
    "\n",
    "    # Create versions of XX and Xy which are just those matrices times two\n",
    "    XX2 = XX * 2\n",
    "    Xy2 = Xy * 2\n",
    "\n",
    "    #@unpack maxIter, optTol, zeroThreshold = control()\n",
    "\n",
    "    # Go through all iteration\n",
    "    while m<maxIter\n",
    "\n",
    "        # Save the last set of weights (the .copy() is important, otherwise\n",
    "        # beta_old will be updated every time beta is changed during the\n",
    "        # following loop)\n",
    "        beta_old = copy(beta)\n",
    "\n",
    "        # Go through all parameters\n",
    "        for j in 1:p\n",
    "            \n",
    "            # Calculate the shoot\n",
    "            S0 = sum( XX2[j, :].*beta ) - XX2[j, j].*beta[j] - Xy2[j]\n",
    "\n",
    "            # Update the weights\n",
    "            if sum(isnothing(XX)) >= 1\n",
    "                beta[j] = 0\n",
    "\n",
    "            elseif S0 >lmbda[j]\n",
    "                beta[j] = (lmbda[j] - S0) / XX2[j,j]\n",
    "\n",
    "            elseif S0 < -lmbda[j]\n",
    "                beta[j] = (-lmbda[j] - S0) / XX2[j,j]\n",
    "\n",
    "            elseif broadcast(abs, S0) <= lmbda[j]\n",
    "                beta[j] = 0\n",
    "\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Add the updated weights to the history of weights\n",
    "        wp = hcat(wp, beta)\n",
    "\n",
    "        # Check whether the weights are within tolerance\n",
    "        if sum(broadcast(abs, beta - beta_old)) < optTol\n",
    "            # If so, break the while loop\n",
    "            break\n",
    "        end\n",
    "\n",
    "        # Increase the iteration counter\n",
    "        m = m + 1\n",
    "    end\n",
    "\n",
    "    # Set the final weights to the last updated weights\n",
    "    w = beta   \n",
    "\n",
    "    # Set weights which are within zeroThreshold to zero\n",
    "    w[broadcast(abs, w) .< zeroThreshold] .= 0\n",
    "    \n",
    "    #return beta,  w\n",
    "    return Dict(\"coefficients\" => w, \"coef_list\" => wp, \"num_it\" => m)\n",
    "    #return w, wp, m\n",
    "    #return XX2, Xy2\n",
    "    \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5344b340-1d13-4d94-9c78-f4d8426445e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lambdaCalculation (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lambdaCalculation(     ; homoskedastic::Bool=false, X_dependent_lambda::Bool=false,\n",
    "                                lambda_start=nothing, c::Float64=1.1, gamma::Float64=0.1, \n",
    "                                numSim::Int=5000, y=nothing, x=nothing, par::Bool=true, \n",
    "                                corecap::Float64=Inf, fix_seed::Bool=true)\n",
    "    # Get number of observations n and number of variables p\n",
    "    n, p = size(x)\n",
    "\n",
    "    # Get number of simulations to use (if simulations are necessary)\n",
    "    R = numSim\n",
    "\n",
    "    # Go through all possible combinations of homoskedasticy/heteroskedasticity\n",
    "    # and X-dependent or independent error terms. The first two cases are\n",
    "    # special cases: Handling the case there homoskedastic was set to None, and\n",
    "    # where lambda_start was provided.\n",
    "    #\n",
    "        \n",
    "    # 1) If homoskedastic was set to None (special case)\n",
    "    if (isnothing(homoskedastic))\n",
    "\n",
    "        # Initialize lambda\n",
    "        lmbda0 = lambda_start\n",
    "\n",
    "        Ups0 = (1 /sqrt(n)) * sqrt.((y.^2)'*(x.^2))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # 2) If lambda_start was provided (special case)\n",
    "    elseif (isnothing(lambda_start)) == 0\n",
    "        \n",
    "        # Check whether a homogeneous penalty term was provided (a scalar)\n",
    "        if maximum(size(lambda_start)) == 1\n",
    "            # If so, repeat that p times as the penalty term\n",
    "            lmbda = ones(p,1).*lambda_start\n",
    "\n",
    "        else\n",
    "            # Otherwise, use the provided vector of penalty terms as is\n",
    "            lmbda = lambda_start\n",
    "        end\n",
    "\n",
    "    # 3) Homoskedastic and X-independent\n",
    "    elseif homoskedastic == true &&  X_dependent_lambda == false\n",
    "\n",
    "        # Initilaize lambda\n",
    "        lmbda0 = 2 * c * sqrt(n) * quantile(Normal(0.0, 1.0),1 - gamma/(2*p))\n",
    "\n",
    "        # Use ddof=1(corrected = true in Julia) to be consistent with R's var() function (in Julia by defaul the DDF is N-1)\n",
    "        Ups0 = sqrt(var(y, corrected = true))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = zeros(p,1) .+ lmbda0 * Ups0\n",
    "\n",
    "    # 4) Homoskedastic and X-dependent\n",
    "    elseif homoskedastic == true && X_dependent_lambda == true\n",
    "\n",
    "        psi = mean.(eachcol(x.^2))\n",
    "        tXtpsi = (x' ./ sqrt(psi))'\n",
    "\n",
    "        R = 5000\n",
    "        sim = zeros(R,1)\n",
    "\n",
    "        for l in 1:R\n",
    "                g = reshape(repeat(randn(n), inner = p),(p, n))'\n",
    "                sim[l] = n * maximum(2*abs.(mean.(eachcol(tXtpsi.* g))))\n",
    "        end\n",
    "\n",
    "        # Initialize lambda based on the simulated quantiles\n",
    "        lmbda0 = c*quantile(vec(sim), 1 - gamma)\n",
    "\n",
    "        Ups0 = sqrt(var(y, corrected = true))\n",
    "\n",
    "        # Calculate the final vector of penalty terms\n",
    "        lmbda = zeros(p,1) .+ lmbda0 * Ups0\n",
    "\n",
    "    # 5) Heteroskedastic and X-independent\n",
    "    elseif homoskedastic == false &&  X_dependent_lambda == false\n",
    "\n",
    "        # The original includes the comment, \"1=num endogenous variables\"\n",
    "        lmbda0 = 2 * c * sqrt(n) * quantile(Normal(0.0, 1.0),1 - gamma/(2*p*1))\n",
    "\n",
    "        Ups0 = (1 /sqrt(n)) * sqrt.((y.^2)'*(x.^2))'\n",
    "        \n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    # 6) Heteroskedastic and X-dependent\n",
    "    elseif homoskedastic == false &&  X_dependent_lambda == true\n",
    "\n",
    "        eh = y\n",
    "        ehat = reshape(repeat(eh, inner = p),(p, n))'\n",
    "\n",
    "        xehat = x.*ehat\n",
    "        psi = mean.(eachcol(xehat.^2))'\n",
    "        tXehattpsi = (xehat./sqrt.(psi))\n",
    "\n",
    "        R = 5000\n",
    "        sim = zeros(R,1)\n",
    "\n",
    "        for l in 1:R\n",
    "                g = reshape(repeat(randn(n), inner = p),(p, n))'\n",
    "                sim[l] = n * maximum(2*abs.(mean.(eachcol(tXtpsi.* g))))\n",
    "        end\n",
    "\n",
    "        # Initialize lambda based on the simulated quantiles\n",
    "        lmbda0 = c*quantile(vec(sim), 1 - gamma)\n",
    "\n",
    "        Ups0 = (1 /sqrt(n)) * sqrt.((y.^2)'*(x.^2))\n",
    "\n",
    "        lmbda = lmbda0 * Ups0\n",
    "\n",
    "    end\n",
    "    return Dict(\"lambda0\" => lmbda0, \"lambda\" => lmbda, \"Ups0\" => Ups0) \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0497c04-bef1-49c0-9820-8096eddcbcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rlasso_arg"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.@kwdef mutable struct rlasso_arg\n",
    "    x::DataFrame\n",
    "    y::DataFrame\n",
    "    colnames::Nothing = nothing\n",
    "    #rlasso_arg_v2(colnames=nothing) = new(colnames)\n",
    "    post::Bool=true\n",
    "    intercept::Bool=true\n",
    "    model::Bool=true\n",
    "    homoskedastic::Bool=false\n",
    "    X_dependent_lambda::Bool=false\n",
    "    lambda_start::Nothing = nothing\n",
    "    #rlasso_arg_v2(lambda_start=nothing) = new(lambda_start)\n",
    "    c::Float64=1.1\n",
    "    gamma::Nothing = nothing\n",
    "    #rlasso_arg_v2(lambda_start=nothing) = new(gamma)\n",
    "    numSim::Int=5000\n",
    "    numIter::Int=15\n",
    "    tol::Float64=10^(-5)\n",
    "    threshold::Float64=-Inf\n",
    "    par::Bool=true\n",
    "    corecap::Float64=Inf\n",
    "    fix_seed::Bool=true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed0fef64-d8e6-4862-b533-4c4a49e10bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rlasso (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rlasso(self::rlasso_arg)\n",
    "    \n",
    "    # Import relevant packages for splitting data\n",
    "    #using LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, Tables, TableOperations, StatsBase, FreqTables, DataFrames\n",
    "    \n",
    "    # Initialize internal variables\n",
    "    if self.x isa DataFrame && isnothing(self.colnames)\n",
    "        colnames = names(self.x)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    x = Matrix(self.x)\n",
    "    y = vec(Matrix(self.y))\n",
    "    \n",
    "    n = size(x)[1]\n",
    "    p = size(x)[2]\n",
    "    \n",
    "    if self.x isa DataFrame ==0 && isnothing(self.colnames)\n",
    "        V = []\n",
    "                \n",
    "        for i in 1:p\n",
    "            a = \"V\" * string(i)\n",
    "            V = append!(V, [a])\n",
    "        end\n",
    "        \n",
    "        colnames  = V\n",
    "    else\n",
    "        colnames = colnames\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # Unused line in the original code\n",
    "    # ind_names = np.arange(self.p) + 1\n",
    "    \n",
    "    post               = self.post\n",
    "    intercept          = self.intercept\n",
    "    model              = self.model\n",
    "    homoskedastic      = self.homoskedastic\n",
    "    X_dependent_lambda = self.X_dependent_lambda\n",
    "    lambda_start       = self.lambda_start\n",
    "    c                  = self.c\n",
    "\n",
    "    if isnothing(self.gamma)\n",
    "        gamma = .1 / log(n)\n",
    "    \n",
    "    else\n",
    "        gamma = self.gamma\n",
    "    end\n",
    "    \n",
    "    numSim    = self.numSim\n",
    "    numIter   = self.numIter\n",
    "    tol       = self.tol\n",
    "    threshold = self.threshold\n",
    "\n",
    "    par       = self.par\n",
    "    corecap   = self.corecap\n",
    "    fix_seed  = self.fix_seed\n",
    "    \n",
    "    if self.post == false && isnothing(self.c)\n",
    "        c = 0.5\n",
    "    end\n",
    "    \n",
    "    if ( (self.post == false) && (self.homoskedastic == false)\n",
    "            && (self.X_dependent_lambda == false)\n",
    "            && (isnothing(self.lambda_start)) \n",
    "            && (self.c == 1.1)\n",
    "            && (self.gamma == 0.1 / log(n)) )\n",
    "        \n",
    "        c = .5\n",
    "    end\n",
    "    \n",
    "    # For now, instantiate estimate as None\n",
    "    est = nothing\n",
    "    \n",
    "    \n",
    "    # Calculate robust LASSO coefficients\n",
    "    if self.intercept == true\n",
    "        meanx = mean.(eachcol(x))\n",
    "        x = x - ones(n, 1) * mean.(eachcol(x))'\n",
    "        mu = mean(y)\n",
    "        y = y .- mu\n",
    "        \n",
    "    else\n",
    "        meanx = zeros(p, 1)\n",
    "        mu = 0\n",
    "    end\n",
    "    \n",
    "    normx = sqrt.(var(x, corrected = true, dims = 2))\n",
    "    Psi = mean.(eachcol(x.^2))\n",
    "    ind = zeros(Bool, p)\n",
    "    \n",
    "    XX = x'*x\n",
    "    Xy = x'*y\n",
    "    \n",
    "    startingval = init_values(x, y)[1]\n",
    "    \n",
    "    pen = lambdaCalculation(;homoskedastic=homoskedastic,\n",
    "                                X_dependent_lambda=X_dependent_lambda,\n",
    "                                lambda_start=lambda_start, c=c,\n",
    "                                gamma=gamma, numSim=numSim,\n",
    "                                y=startingval, x=x, par=par,\n",
    "                                corecap=corecap, fix_seed=fix_seed)\n",
    "\n",
    "    lmbda = vec(pen[\"lambda\"])\n",
    "    lmbda_half = lmbda/2\n",
    "    Ups0 = vec(pen[\"Ups0\"])\n",
    "    Ups1 = vec(pen[\"Ups0\"])\n",
    "    lmbda0 = pen[\"lambda0\"]\n",
    "    \n",
    "    mm = 1\n",
    "    s0 = sqrt.(var(y, corrected = true, dims = 1))\n",
    "    \n",
    "    while mm <= numIter\n",
    "        if mm == 1 && self.post\n",
    "#             coefTemp = LassoShooting_fit(x, y, lmbda/2, XX=XX,\n",
    "#                                       Xy=Xy)[\"coefficients\"]\n",
    "            \n",
    "              global coefTemp = LassoShooting_fit(  ;x=x, y=y, \n",
    "                                lmbda=lmbda_half, \n",
    "                                maxIter = 1000, \n",
    "                                optTol = 10^(-5), \n",
    "                                zeroThreshold = 10^(-6),\n",
    "                                XX = XX, \n",
    "                                Xy = Xy, \n",
    "                                beta_start = nothing)[\"coefficients\"]\n",
    "        else\n",
    "              global coefTemp = LassoShooting_fit(  ;x=x, y=y, \n",
    "                                lmbda=lmbda, \n",
    "                                maxIter = 1000, \n",
    "                                optTol = 10^(-5), \n",
    "                                zeroThreshold = 10^(-6),\n",
    "                                XX = XX, \n",
    "                                Xy = Xy, \n",
    "                                beta_start = nothing)[\"coefficients\"]\n",
    "                \n",
    "        end\n",
    "        \n",
    "        global coefTemp[isnan.(coefTemp)] .= 0\n",
    "            \n",
    "        global ind1 =  broadcast(abs, coefTemp) .> 0\n",
    "        \n",
    "        global x1 = x[:, ind1]\n",
    "        \n",
    "        if size(x1)[2] == 0\n",
    "            if intercept\n",
    "                intercept_value = mean(y .+ mu)\n",
    "                \n",
    "                coefs = zeroz(p+1, 1)\n",
    "                coefs = DataFrame([ append!([\"Intercept\"], colnames), coefs ], :auto)\n",
    "               \n",
    "                #coef = \n",
    "            \n",
    "            else\n",
    "                intercept_value = mean(y)\n",
    "                \n",
    "                coefs = zeroz(p, 1)\n",
    "                \n",
    "                coefs = DataFrame([ colnames, coefs ], :auto)\n",
    "            end\n",
    "            \n",
    "            \n",
    "            global est = Dict(\"coefficients\"=> coefs,\n",
    "                    \"beta\"=> zeroz(p, 1),\n",
    "                    \"intercept\"=> intercept_value,\n",
    "                    \"index\"=> DataFrame([ colnames, zeros(Bool, p) ], :auto),\n",
    "                    \"lambda\"=> lmbda,\n",
    "                    \"lambda0\"=> lmbda0,\n",
    "                    \"loadings\"=> Ups0,\n",
    "                    \"residuals\"=> y .- mean(y),\n",
    "                    \"sigma\"=> var(y, corrected = true, dims = 1),\n",
    "                    \"iter\"=> mm,\n",
    "                    #\"call\"=> Not a Python option\n",
    "                    \"options\"=> Dict(\"post\"=> post, \"intercept\"=> intercept,\n",
    "                                \"ind.scale\"=> ind, \"mu\"=> mu, \"meanx\"=> meanx)\n",
    "                   )\n",
    "                \n",
    "            if self.model\n",
    "                    est[\"model\"] = x\n",
    "            else\n",
    "                est[\"model\"] = nothing\n",
    "            \n",
    "            end \n",
    "            \n",
    "            est[\"tss\"] = sum((y .- mean(y)).^2)\n",
    "            est[\"rss\"] = sum((y .- mean(y)).^2)\n",
    "            est[\"dev\"] = y .- mean(y)\n",
    "        \n",
    "        end \n",
    "        \n",
    "        # Refinement variance estimation\n",
    "        if self.post\n",
    "            \n",
    "            reg = lm(x1, y)\n",
    "            \n",
    "            coefT = coef( lm(x1, y) )\n",
    "            \n",
    "            coefT[isnan.(coefT)] .= 0\n",
    "            \n",
    "            global e1 = y - x1*coef( lm(x1, y) )\n",
    "            \n",
    "            coefTemp[ind1] = coefT\n",
    "            \n",
    "        else\n",
    "            global e1 = y - x1*coefTemp[ind1]\n",
    "            \n",
    "        end\n",
    "        \n",
    "        s1 = sqrt.(var(e1, corrected = true, dims = 1))\n",
    "        #s5 = sqrt.(var(y, corrected = true, dims = 1))\n",
    "        \n",
    "                \n",
    "        # Homoskedastic and X-independent\n",
    "        if (\n",
    "                    (self.homoskedastic == true) \n",
    "                    && (self.X_dependent_lambda == false)\n",
    "            )\n",
    "            \n",
    "            Ups1 = s1 * Psi\n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "            \n",
    "        # Homoskedastic and X-dependent\n",
    "        elseif (\n",
    "                    (self.homoskedastic == true)\n",
    "                    && (self.X_dependent_lambda == true)\n",
    "            )\n",
    "\n",
    "            Ups1 = s1 * Psi\n",
    "\n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "\n",
    "        # Heteroskedastic and X-independent\n",
    "        elseif (\n",
    "                (self.homoskedastic == false)\n",
    "                && (self.X_dependent_lambda == false)\n",
    "            )\n",
    "                        \n",
    "            Ups1 =  (1/sqrt(n)) * sqrt.((e1.^2)' * x.^2)\n",
    "            \n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "        \n",
    "        # Heteroskedastic and X-dependent\n",
    "        elseif (\n",
    "                (self.homoskedastic == false)\n",
    "                && (self.X_dependent_lambda == true)\n",
    "                )\n",
    "            \n",
    "            lc = lambdaCalculation(homoskedastic=homoskedastic,\n",
    "                       X_dependent_lambda=X_dependent_lambda,\n",
    "                       lambda_start=lambda_start,\n",
    "                       c=c, gamma=gamma,\n",
    "                       numSim=numSim, y=e1, x=x,\n",
    "                       par=par, corecap=corecap,\n",
    "                       fix_seed=fix_seed)\n",
    "\n",
    "            Ups1 = lc[\"Ups0\"]\n",
    "\n",
    "            lmbda = lc[\"lambda\"]\n",
    "        \n",
    "        # If homoskedastic is set to None\n",
    "        elseif isnothing(self.homoskedastic)\n",
    "            \n",
    "            Ups1 =  (\n",
    "                    (1/sqrt(n)) * sqrt.((e1.^2) * x.^2)\n",
    "                )\n",
    "            \n",
    "            lmbda = pen[\"lambda0\"] * Ups1\n",
    "        end\n",
    "        \n",
    "        mm = mm + 1\n",
    "        \n",
    "        if broadcast(abs, s0 - s1)[1] < self.tol\n",
    "            break\n",
    "            \n",
    "        end\n",
    "        \n",
    "        s0 = s1\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if size(x1)[2] == 0\n",
    "        coefTemp = None\n",
    "        ind1 = zeros(p, 1)\n",
    "    end\n",
    "    \n",
    "    global coefTemp = coefTemp\n",
    "    \n",
    "    coefTemp[broadcast(abs, coefTemp) .< threshold] .= 0\n",
    "    \n",
    "    coefTemp_df = DataFrame([ colnames, coefTemp ], :auto)\n",
    "\n",
    "    global ind1 = ind1\n",
    "    \n",
    "    ind1_df = DataFrame([ colnames, ind1 ], :auto)\n",
    "    \n",
    "    if self.intercept\n",
    "        \n",
    "        if isnothing(mu)\n",
    "            mu = 0\n",
    "        end\n",
    "        \n",
    "        if isnothing(meanx)\n",
    "            meanx = zeros( size(coefTemp)[1], 1)\n",
    "        end\n",
    "        \n",
    "        if sum(ind) == 0\n",
    "            intercept_value = mu - sum(meanx .* coefTemp)\n",
    "        else\n",
    "            intercept_value = mu - sum(meanx .* coefTemp)\n",
    "        end\n",
    "    \n",
    "    else\n",
    "        intercept_value = NaN\n",
    "    end\n",
    "    \n",
    "    #s1 = sqrt.(var(e1, corrected = true, dims = 1))\n",
    "    \n",
    "    if self.intercept\n",
    "        beta = vcat(intercept_value, coefTemp)\n",
    "        \n",
    "        beta = DataFrame([ append!([\"Intercept\"], colnames), beta ], :auto)\n",
    "    \n",
    "    else\n",
    "        beta = coefTemp\n",
    "        \n",
    "    end\n",
    "    \n",
    "    s1 = sqrt.(var(e1, corrected = true, dims = 1))\n",
    "    \n",
    "    \n",
    "    est = Dict(\n",
    "    \"coefficients\"=> beta,\n",
    "    \"beta\"=> DataFrame([ colnames, coefTemp ], :auto), \n",
    "    \"intercept\"=> intercept_value,\n",
    "    \"index\"=> ind1,\n",
    "    \"lambda\"=> DataFrame([ colnames, vec(lmbda) ], :auto),\n",
    "    \"lambda0\"=> lmbda0,\n",
    "    \"loadings\"=> Ups1,\n",
    "    \"residuals\"=> e1,\n",
    "    \"sigma\"=> s1,\n",
    "    \"iter\"=> mm,\n",
    "    #\"call\"=> Not a Python option\n",
    "    \"options\"=> Dict(\"post\"=> self.post, \"intercept\"=> self.intercept,\n",
    "                \"ind.scale\"=> ind, \"mu\"=> mu, \"meanx\"=> meanx),\n",
    "    \"model\"=> model\n",
    "    )\n",
    "    \n",
    "    if model\n",
    "        x = x + ones(n, 1) * mean.(eachcol(x))'\n",
    "        \n",
    "        est[\"model\"] = x\n",
    "        \n",
    "    else\n",
    "        est[\"model\"] = nothing\n",
    "        \n",
    "    end\n",
    "    \n",
    "    est[\"tss\"] = sum((y .- mean(y)).^2)\n",
    "    est[\"rss\"] = sum((y .- mean(y)).^2)\n",
    "    est[\"dev\"] = y .- mean(y)\n",
    "    est[\"Xy\"] = Xy\n",
    "    est[\"startingval\"] = startingval\n",
    "    est[\"pen\"] = pen\n",
    "    est[\"x1\"] = x1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   return est\n",
    "   #return Dict(\"reg\" => reg)\n",
    "   #return coefTemp\n",
    "   #return colnames, coefTemp, lmbda\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8eaba-7e53-4515-a018-2b14d0eef6bd",
   "metadata": {},
   "source": [
    "## rlasso testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e26033e-c60c-42ea-9502-f8a24db7974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f65094c4-cfda-4d22-a8cb-9e9972f3a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}:\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────\n",
       "          Coef.  Std. Error      t  Pr(>|t|)    Lower 95%    Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────\n",
       "x1   0.00289408  0.00239153   1.21    0.2295  -0.00186013   0.00764829\n",
       "x2  -0.0572642   0.023258    -2.46    0.0158  -0.1035      -0.0110289\n",
       "x3   0.132428    0.0744655    1.78    0.0789  -0.015604     0.280461\n",
       "x4   0.0845833   0.246612     0.34    0.7324  -0.405665     0.574832\n",
       "──────────────────────────────────────────────────────────────────────\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_read = load(\"data/GrowthData.RData\")\n",
    "\n",
    "# Since growth_read is a dictionary, we check if there is a key called \"GrowthData\", the one we need for our analyze\n",
    "haskey(growth_read, \"GrowthData\")\n",
    "# Now we save that dataframe with a new name\n",
    "growth = growth_read[\"GrowthData\"]\n",
    "names(growth)\n",
    "\n",
    "Y = growth[!, \"Outcome\"]\n",
    "X_2 = select(growth, Not([\"Outcome\"]))\n",
    "X_2 = convert(Matrix, Matrix(X_2[:, 2:5]))\n",
    "lmbda = randn(size(X_2)[2])\n",
    "lm(X_2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76de51ce-df2a-4fb4-a3df-de90398dc85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  0.007895524013611042\n",
       " -0.107661184127788\n",
       "  0.0\n",
       "  0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoShooting_fit(x = X_2, y = Y[:, 1], lmbda = lmbda)[\"coefficients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1010d459-b3ef-48b9-b6f0-a15c62bf41d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rlasso_arg\n",
       "  x: DataFrame\n",
       "  y: DataFrame\n",
       "  colnames: Nothing nothing\n",
       "  post: Bool true\n",
       "  intercept: Bool true\n",
       "  model: Bool true\n",
       "  homoskedastic: Bool false\n",
       "  X_dependent_lambda: Bool false\n",
       "  lambda_start: Nothing nothing\n",
       "  c: Float64 1.1\n",
       "  gamma: Nothing nothing\n",
       "  numSim: Int64 5000\n",
       "  numIter: Int64 15\n",
       "  tol: Float64 1.0000000000000006e-5\n",
       "  threshold: Float64 -Inf\n",
       "  par: Bool true\n",
       "  corecap: Float64 Inf\n",
       "  fix_seed: Bool true\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rlasso_arg(x = X_2, y = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21ea9e7b-96a1-4b8c-9158-2565e4aaaff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 19 entries:\n",
       "  \"tss\"          => 0.23435\n",
       "  \"dev\"          => [-0.0696852, 0.0551231, 0.021702, 0.0187397, -0.0174199, 0.…\n",
       "  \"model\"        => [-1.11123 0.114953 -0.0666109 0.0155539; -0.873113 0.445353…\n",
       "  \"loadings\"     => [0.038991 0.0105688 0.00313556 0.0007937]\n",
       "  \"sigma\"        => [0.0477366]\n",
       "  \"lambda0\"      => 57.8734\n",
       "  \"lambda\"       => \u001b[1m4×2 DataFrame\u001b[0m…\n",
       "  \"intercept\"    => 0.0581009\n",
       "  \"Xy\"           => [0.0941175, -0.417365, 0.0764848, -0.0198564]\n",
       "  \"iter\"         => 4\n",
       "  \"residuals\"    => [-0.0609987, 0.0887764, 0.00895057, 0.0210787, -0.017023, -…\n",
       "  \"rss\"          => 0.23435\n",
       "  \"index\"        => Bool[0, 1, 0, 0]\n",
       "  \"beta\"         => \u001b[1m4×2 DataFrame\u001b[0m…\n",
       "  \"options\"      => Dict{String, Any}(\"intercept\"=>true, \"post\"=>true, \"meanx\"=…\n",
       "  \"x1\"           => [0.114953; 0.445353; … ; -0.168747; -0.168747;;]\n",
       "  \"pen\"          => Dict{String, Any}(\"lambda0\"=>57.8734, \"lambda\"=>[2.20141; 0…\n",
       "  \"startingval\"  => [-0.0684174, 0.0819642, 0.0240059, 0.0198264, -0.0312296, -…\n",
       "  \"coefficients\" => \u001b[1m5×2 DataFrame\u001b[0m…"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = rlasso(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8ee674a-09e2-4719-a5c7-6aac4c9f0a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th></tr><tr><th></th><th>String</th><th>Float64</th></tr></thead><tbody><p>5 rows × 2 columns</p><tr><th>1</th><td>Intercept</td><td>0.0581009</td></tr><tr><th>2</th><td>x1</td><td>0.0</td></tr><tr><th>3</th><td>x2</td><td>-0.0755655</td></tr><tr><th>4</th><td>x3</td><td>0.0</td></tr><tr><th>5</th><td>x4</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& x1 & x2\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Intercept & 0.0581009 \\\\\n",
       "\t2 & x1 & 0.0 \\\\\n",
       "\t3 & x2 & -0.0755655 \\\\\n",
       "\t4 & x3 & 0.0 \\\\\n",
       "\t5 & x4 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x1        \u001b[0m\u001b[1m x2         \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String    \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │ Intercept   0.0581009\n",
       "   2 │ x1          0.0\n",
       "   3 │ x2         -0.0755655\n",
       "   4 │ x3          0.0\n",
       "   5 │ x4          0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1[\"coefficients\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662402ff-0583-4471-b1cf-4f3dd90a8ed6",
   "metadata": {},
   "source": [
    "## rlassoIV testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e854401d-57ca-4537-a055-c85409dab682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>GDP</th><th>Exprop</th><th>Mort</th><th>Latitude</th><th>Neo</th><th>Africa</th><th>Asia</th><th>Namer</th><th>Samer</th><th>logMort</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int32</th><th>Int32</th><th>Int32</th><th>Int32</th><th>Int32</th><th>Float64</th></tr></thead><tbody><p>64 rows × 11 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>8.39</td><td>6.5</td><td>78.2</td><td>0.3111</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>4.35927</td></tr><tr><th>2</th><td>7.77</td><td>5.36</td><td>280.0</td><td>0.1367</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>5.63479</td></tr><tr><th>3</th><td>9.13</td><td>6.39</td><td>68.9</td><td>0.3778</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4.23266</td></tr><tr><th>4</th><td>9.9</td><td>9.32</td><td>8.55</td><td>0.3</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2.14593</td></tr><tr><th>5</th><td>9.29</td><td>7.5</td><td>85.0</td><td>0.2683</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.44265</td></tr><tr><th>6</th><td>6.88</td><td>5.14</td><td>71.41</td><td>0.2667</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>4.26844</td></tr><tr><th>7</th><td>7.93</td><td>5.64</td><td>71.0</td><td>0.1889</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4.26268</td></tr><tr><th>8</th><td>8.73</td><td>7.91</td><td>71.0</td><td>0.1111</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4.26268</td></tr><tr><th>9</th><td>6.85</td><td>4.45</td><td>280.0</td><td>0.1444</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>5.63479</td></tr><tr><th>10</th><td>7.5</td><td>6.45</td><td>280.0</td><td>0.6667</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>5.63479</td></tr><tr><th>11</th><td>9.99</td><td>9.73</td><td>16.1</td><td>0.6667</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2.77882</td></tr><tr><th>12</th><td>9.34</td><td>7.82</td><td>68.9</td><td>0.3333</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4.23266</td></tr><tr><th>13</th><td>8.81</td><td>7.32</td><td>71.0</td><td>0.0444</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4.26268</td></tr><tr><th>14</th><td>7.42</td><td>4.68</td><td>240.0</td><td>0.0111</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>5.48064</td></tr><tr><th>15</th><td>8.79</td><td>7.05</td><td>78.1</td><td>0.1111</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.35799</td></tr><tr><th>16</th><td>7.44</td><td>7.0</td><td>668.0</td><td>0.0889</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>6.50429</td></tr><tr><th>17</th><td>8.36</td><td>6.18</td><td>130.0</td><td>0.2111</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.86753</td></tr><tr><th>18</th><td>8.47</td><td>6.55</td><td>71.0</td><td>0.0222</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>4.26268</td></tr><tr><th>19</th><td>7.95</td><td>6.77</td><td>67.8</td><td>0.3</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>4.21656</td></tr><tr><th>20</th><td>7.95</td><td>5.0</td><td>78.1</td><td>0.15</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.35799</td></tr><tr><th>21</th><td>6.11</td><td>5.73</td><td>26.0</td><td>0.0889</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3.2581</td></tr><tr><th>22</th><td>8.9</td><td>7.82</td><td>280.0</td><td>0.0111</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>5.63479</td></tr><tr><th>23</th><td>7.27</td><td>8.27</td><td>1470.0</td><td>0.1476</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>7.29302</td></tr><tr><th>24</th><td>7.37</td><td>6.27</td><td>668.0</td><td>0.0889</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>6.50429</td></tr><tr><th>25</th><td>8.29</td><td>5.14</td><td>71.0</td><td>0.17</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.26268</td></tr><tr><th>26</th><td>7.49</td><td>6.55</td><td>483.0</td><td>0.1222</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>6.18002</td></tr><tr><th>27</th><td>7.9</td><td>5.89</td><td>32.18</td><td>0.0556</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>3.47135</td></tr><tr><th>28</th><td>7.15</td><td>3.73</td><td>130.0</td><td>0.2111</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.86753</td></tr><tr><th>29</th><td>7.69</td><td>5.32</td><td>78.1</td><td>0.1667</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>4.35799</td></tr><tr><th>30</th><td>10.05</td><td>8.14</td><td>14.9</td><td>0.2461</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2.70136</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& GDP & Exprop & Mort & Latitude & Neo & Africa & Asia & Namer & Samer & logMort & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Int32 & Int32 & Int32 & Int32 & Int32 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 8.39 & 6.5 & 78.2 & 0.3111 & 0 & 1 & 0 & 0 & 0 & 4.35927 & $\\dots$ \\\\\n",
       "\t2 & 7.77 & 5.36 & 280.0 & 0.1367 & 0 & 1 & 0 & 0 & 0 & 5.63479 & $\\dots$ \\\\\n",
       "\t3 & 9.13 & 6.39 & 68.9 & 0.3778 & 0 & 0 & 0 & 0 & 1 & 4.23266 & $\\dots$ \\\\\n",
       "\t4 & 9.9 & 9.32 & 8.55 & 0.3 & 1 & 0 & 0 & 0 & 0 & 2.14593 & $\\dots$ \\\\\n",
       "\t5 & 9.29 & 7.5 & 85.0 & 0.2683 & 0 & 0 & 0 & 1 & 0 & 4.44265 & $\\dots$ \\\\\n",
       "\t6 & 6.88 & 5.14 & 71.41 & 0.2667 & 0 & 0 & 1 & 0 & 0 & 4.26844 & $\\dots$ \\\\\n",
       "\t7 & 7.93 & 5.64 & 71.0 & 0.1889 & 0 & 0 & 0 & 0 & 1 & 4.26268 & $\\dots$ \\\\\n",
       "\t8 & 8.73 & 7.91 & 71.0 & 0.1111 & 0 & 0 & 0 & 0 & 1 & 4.26268 & $\\dots$ \\\\\n",
       "\t9 & 6.85 & 4.45 & 280.0 & 0.1444 & 0 & 1 & 0 & 0 & 0 & 5.63479 & $\\dots$ \\\\\n",
       "\t10 & 7.5 & 6.45 & 280.0 & 0.6667 & 0 & 1 & 0 & 0 & 0 & 5.63479 & $\\dots$ \\\\\n",
       "\t11 & 9.99 & 9.73 & 16.1 & 0.6667 & 1 & 0 & 0 & 1 & 0 & 2.77882 & $\\dots$ \\\\\n",
       "\t12 & 9.34 & 7.82 & 68.9 & 0.3333 & 0 & 0 & 0 & 0 & 1 & 4.23266 & $\\dots$ \\\\\n",
       "\t13 & 8.81 & 7.32 & 71.0 & 0.0444 & 0 & 0 & 0 & 0 & 1 & 4.26268 & $\\dots$ \\\\\n",
       "\t14 & 7.42 & 4.68 & 240.0 & 0.0111 & 0 & 1 & 0 & 0 & 0 & 5.48064 & $\\dots$ \\\\\n",
       "\t15 & 8.79 & 7.05 & 78.1 & 0.1111 & 0 & 0 & 0 & 1 & 0 & 4.35799 & $\\dots$ \\\\\n",
       "\t16 & 7.44 & 7.0 & 668.0 & 0.0889 & 0 & 1 & 0 & 0 & 0 & 6.50429 & $\\dots$ \\\\\n",
       "\t17 & 8.36 & 6.18 & 130.0 & 0.2111 & 0 & 0 & 0 & 1 & 0 & 4.86753 & $\\dots$ \\\\\n",
       "\t18 & 8.47 & 6.55 & 71.0 & 0.0222 & 0 & 0 & 0 & 0 & 1 & 4.26268 & $\\dots$ \\\\\n",
       "\t19 & 7.95 & 6.77 & 67.8 & 0.3 & 0 & 1 & 0 & 0 & 0 & 4.21656 & $\\dots$ \\\\\n",
       "\t20 & 7.95 & 5.0 & 78.1 & 0.15 & 0 & 0 & 0 & 1 & 0 & 4.35799 & $\\dots$ \\\\\n",
       "\t21 & 6.11 & 5.73 & 26.0 & 0.0889 & 0 & 1 & 0 & 0 & 0 & 3.2581 & $\\dots$ \\\\\n",
       "\t22 & 8.9 & 7.82 & 280.0 & 0.0111 & 0 & 1 & 0 & 0 & 0 & 5.63479 & $\\dots$ \\\\\n",
       "\t23 & 7.27 & 8.27 & 1470.0 & 0.1476 & 0 & 1 & 0 & 0 & 0 & 7.29302 & $\\dots$ \\\\\n",
       "\t24 & 7.37 & 6.27 & 668.0 & 0.0889 & 0 & 1 & 0 & 0 & 0 & 6.50429 & $\\dots$ \\\\\n",
       "\t25 & 8.29 & 5.14 & 71.0 & 0.17 & 0 & 0 & 0 & 1 & 0 & 4.26268 & $\\dots$ \\\\\n",
       "\t26 & 7.49 & 6.55 & 483.0 & 0.1222 & 0 & 1 & 0 & 0 & 0 & 6.18002 & $\\dots$ \\\\\n",
       "\t27 & 7.9 & 5.89 & 32.18 & 0.0556 & 0 & 0 & 0 & 0 & 1 & 3.47135 & $\\dots$ \\\\\n",
       "\t28 & 7.15 & 3.73 & 130.0 & 0.2111 & 0 & 0 & 0 & 1 & 0 & 4.86753 & $\\dots$ \\\\\n",
       "\t29 & 7.69 & 5.32 & 78.1 & 0.1667 & 0 & 0 & 0 & 1 & 0 & 4.35799 & $\\dots$ \\\\\n",
       "\t30 & 10.05 & 8.14 & 14.9 & 0.2461 & 0 & 0 & 1 & 0 & 0 & 2.70136 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m64×11 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m GDP     \u001b[0m\u001b[1m Exprop  \u001b[0m\u001b[1m Mort    \u001b[0m\u001b[1m Latitude \u001b[0m\u001b[1m Neo   \u001b[0m\u001b[1m Africa \u001b[0m\u001b[1m Asia  \u001b[0m\u001b[1m Namer \u001b[0m\u001b[1m Samer\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Int32 \u001b[0m\u001b[90m Int32  \u001b[0m\u001b[90m Int32 \u001b[0m\u001b[90m Int32 \u001b[0m\u001b[90m Int32\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    8.39     6.5     78.2     0.3111      0       1      0      0  0     ⋯\n",
       "   2 │    7.77     5.36   280.0     0.1367      0       1      0      0  0\n",
       "   3 │    9.13     6.39    68.9     0.3778      0       0      0      0  1\n",
       "   4 │    9.9      9.32     8.55    0.3         1       0      0      0  0\n",
       "   5 │    9.29     7.5     85.0     0.2683      0       0      0      1  0     ⋯\n",
       "   6 │    6.88     5.14    71.41    0.2667      0       0      1      0  0\n",
       "   7 │    7.93     5.64    71.0     0.1889      0       0      0      0  1\n",
       "   8 │    8.73     7.91    71.0     0.1111      0       0      0      0  1\n",
       "   9 │    6.85     4.45   280.0     0.1444      0       1      0      0  0     ⋯\n",
       "  10 │    7.5      6.45   280.0     0.6667      0       1      0      0  0\n",
       "  11 │    9.99     9.73    16.1     0.6667      1       0      0      1  0\n",
       "  ⋮  │    ⋮        ⋮        ⋮        ⋮        ⋮      ⋮       ⋮      ⋮      ⋮   ⋱\n",
       "  55 │    6.25     6.64   145.0     0.0667      0       1      0      0  0\n",
       "  56 │    7.22     6.91   668.0     0.0889      0       1      0      0  0     ⋯\n",
       "  57 │    8.77     7.45    85.0     0.1222      0       0      0      1  0\n",
       "  58 │    8.48     6.45    63.0     0.3778      0       1      0      0  0\n",
       "  59 │    6.97     4.45   280.0     0.0111      0       1      0      0  0\n",
       "  60 │    9.03     7.0     71.0     0.3667      0       0      0      0  1     ⋯\n",
       "  61 │   10.22    10.0     15.0     0.4222      1       0      0      1  0\n",
       "  62 │    9.07     7.14    78.1     0.0889      0       0      0      0  1\n",
       "  63 │    7.28     6.41   140.0     0.1778      0       0      1      0  0\n",
       "  64 │    6.87     3.5    240.0     0.0         0       1      0      0  0     ⋯\n",
       "\u001b[36m                                                   2 columns and 43 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AJR = load(\"data/AJR.RData\")[\"AJR\"]\n",
    "y = AJR.GDP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0e9fa59-8c18-4641-bb9c-dd1849395cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rlassoIVselectX (generic function with 2 methods)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rlassoIVselectX(self::rlassoIV_arg)\n",
    "    \n",
    "    d = Matrix(self.d)\n",
    "    z = Matrix(self.z)\n",
    "    \n",
    "    n = size(y, 1)\n",
    "    numIV = size(z, 2)\n",
    "    Z = hcat(x, z)\n",
    "    lasso_d_x = rlasso(rlasso_arg(x, d, post))\n",
    "    Dr = lasso_d_x[\"residuals\"]\n",
    "    lasso_y_x = rlasso(rlasso_arg(x, y, post))\n",
    "    Yr = lasso_y_x[\"residuals\"]\n",
    "    Zr = zeros(n, numIV)\n",
    "    for i in 1:numIV\n",
    "        lasso_z_x = rlasso(rlasso_arg(x, z[:, i], post))\n",
    "        Zr[:, i] = lasso_z_x[\"residuals\"]\n",
    "    end\n",
    "    \n",
    "    data = DataFrame(Yr = Yr, Dr = Dr, Zr = Zr)\n",
    "    result = reg(data, @formula(Yr ~ (Dr ~ Zr)))\n",
    "    se = FixedEffectModels.coeftable(result).cols[2]\n",
    "    vcov = vcov(result)\n",
    "    coef = coef(result)[1]\n",
    "    res = Dict(\"coefficients\" => coef, \"vcov\" => vcov, \"se\" => se)\n",
    "    \n",
    "    return res\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3b240-a0a6-4b8a-abb0-990e932f309b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
